The expression of emotion in robots is becoming a quite important issue to implement robots able to interact with people in a social context. Following the results obtained by studying emotion expression in humans (e.g., \cite{Venture2014,Ekman2004}), it is possible to notice that most of the works focus on facial expressions (e.g.,~\cite{Breazeal2002}) or on humanoid poses (e.g.,~\cite{Canamero2010}), while the vast majority of robots on the market nowadays are not provided with face, arms and legs. Moreover, the focus is often on the position of limbs, or face elements, more than on the kind of movement that could express emotion, resulting on emotion expressions that could not be broadly used in most platforms.
There are applications where the shape of the robot is constrained by functional needs, such as in the case of home cleaners, lawn mowers, transporters, flying drones, and many others. In all these cases, emotions can be expressed with the only available body, exploiting movement features.

The work presented in this paper focuses on the identification of movement features that could be considered platform independent, thus could be used to express emotions with a wide range of robots. We devised a very simple robot base, with no resemblance to humans or animals, and we proposed its movements to subjects, to identify how they could interpret the movements they could see from a robot in front of them. We performed live trials to keep into consideration factors that could influence the evaluation: the full perception of movement and noise, and the interaction with a physical robot are different if the same scene is lived in first person, or seen on a screen as a movie.

The obtained results enable to say that it is possible to design movements, even for a neutral platform, that could be interpreted as emotional expression, with some differences among emotions, as confirmed also by other experiments~\cite{Sharma2013}.

Finally, we could identify a set of very basic movement features that could be used to express emotions and, most importantly, the range of values for these features that could led to successful implementations.

This paper is organized as follows. The next section provides a brief overview of relevant work related to emotion expression in robots. Section system outlines the platform used in the case studies. The section case studies presents the design and results for all four case studies.