Social environments are intricate spaces where people behave in ways that aim to their acceptance in social groups. Similarly, studies in social robotics have shown that robots acceptance increases when robots project a high social presence~\cite{Heerink08}. The straightest way to fulfill is through imitation of humans' characteristics, such us body form, behaviors and social characteristics. This has inspired most researchers to focus on how express emotions and mental states exploiting anthropomorphic features, in many occasions relying just on faces. However emotions and mental states are not just presented through facial expression, but also by body postures and other features~\cite{Gelder2008}. Nonetheless in psychology has been a clear tendency to study the role of human face in emotion projection~\cite{Ekman2004},~\cite{kleinsmith2012affective} and mental states. This trend has been followed by robotics community, where anthropomorphic faces (e.g.,~\cite{Arras2012},~\cite{Breazeal2002}) and bodies (e.g.,~\cite{Canamero2010},~\cite{haering2011},~\cite{Destephe2013}) have been widely used to convey emotions.
Nevertheless, in many situations the presence of anthropomorphic elements would be out of place and not justified by the main robot's functionalities. Most of the current and future robotics platforms on the market will not require anthropomorphic faces or limbs. In some cases, like, for instance, in floor cleaning robots, anthropomorphic characteristics could even be detrimental to robot's task accomplishment.
This generates the necessity to study other mechanisms that could help to project emotions, which could give people an idea about the robots' state, and engage the user in long term relations.

The amount of works studying non-anthropomorphic features in robotics (e.g.,~\cite{Saerbeck2010,Lakatos2014,Sharma2013,Novika2015}) remains still small in comparison to those that exploit anthropomorphic features. Moreover, these works do not prescribe any specific range of values for the characteristics to be used to express the  implemented emotions. For example, Suk and collaborators~\cite{NAM2014}, in their study, give specific values for acceleration, curvature, but their connection to specific emotions is not given. Rather, they gave a relationship between their features and values in terms of valence and arousal. Another possibility is the use of professional human actors to study how they convey certain emotions. However, a direct mapping between humans and robots is not possible~\cite{Saerbeck2007,Canamero2010} due to robots' physical capabilities. In addition, the significance of the agreement obtained from the studies that used human actors is still on discussion~\cite{Russell2003}. As a consequence is required the necessity to determine to project emotions in non-anthropomorphic platforms.
 
In order to get a better understanding of other features and values that could be used to convey specific emotions, this paper presents an experiment that was designed to identify specific values for some movement features that could be used to express the following emotions, selected among the ones suggested by Ekman as basic~\cite{Ekman2004}: happiness, anger, fear, and sadness. The considered features are: oscillation angle, linear and angular velocity, direction and orientation, identified as independent variables. The perceived emotions and their intensities were considered as dependent variables. It is to be observed that it was given the possibility to the subjects to provide their evaluation of emotional intensity for more than one emotion for each movement of the robot or treatment. The experiment took place in Politecnico di Milano during June and July of 2015, where students from diverse departments were asked to participate without any economical retribution. Krippendorff's alpha agreement~\cite{Krippendorff2007} ($\alpha$) was used to evaluate the agreement among the participants for each treatment. For each of the four emotions was generated a top 10 list based on alpha agreement and perceived intensity. The results suggest that fear is perceived when the robot is looking at the subjects while moving far from them fast. Sadness is associated to slow velocities with slow angular velocity and small oscillation angle. Anger is attributed to fast velocities, both angular and linear, small angle of oscillation and the robot facing the subjects while approaching them.

This paper is organized as follows. The next section introduces previous studies done in human emotion and robot emotions projection. Section~\ref{sec:system} introduces the robotic platform and the software used in the experiment. The experiment's design is explained in section~\ref{sec:experiment}. Finally sections~\ref{sec:experiment} and~\ref{sec:result} present the study done and the obtained results.