This paper presented an experiment made to understand the contribution of angular and linear velocity, body's orientation, and movement direction on humans' perception of emotion expression by a non-anthropomorphic platform. The emotions covered in this experiment correspond to four of the ones enlisted by Ekman~\cite{Ekman2001} as basic emotions: \textit{Anger}, \textit{Happiness}, \textit{Fear} and \textit{Sadness}. To study the contribution of the desired features, a non-anthropomorphic, holonomic platform was used. The experiment was conducted at Politecnico di Milano, and involved 49 participants, each exposed to 20 over 195 movements, selected randomly for each participant. The Krippendorff's alpha agreement~\cite{Krippendorff2007} was used to calculate the consensus about the interpretation of each treatment. Using  alpha and the average emotion intensity attributed to each movement a top 10 movement table for each of the emotions was created.

The values obtained in this experiment could be used as a guide to express emotions in non-anthropomorphic platforms with similar features as the one used in the experiment. It is still needed to cross validate the values and to determine what values from the top ten could more accurately express the desired emotion. It is important to mention that is not expected to have a 100\% of correct emotion recognition by the participants. As it has been observed in previous work in humans and robots, it is not possible to obtain a 100\% of correct recognition due to diverse factors such as current emotional state of the observer. This cross validation would help to reduce the number of feature combinations to the ones with higher possibility of identification. Moreover, additional experiments should be done to obtain analogous values for changes in shape and in different platform's size. Moreover, it is still necessary to study the influence that plays the embodiment on the perception of emotions. This is going to be beneficial to validate this study but it would also generalize other works done on the same direction.

Even thought the number of works studying how to project emotions with robotic platforms is increasing, it is still required a framework that standardize the processes for the design of this endevours. This could is due the following four reasongs. First, there are a variety of emotion theories that could be used as a based to design the experiments or case studies. Hence, researchers must know who to use them correctly and how they are connected among them. For example, the model suggested by Izard~\cite{Izard2007} redefines the idea of basic emotions and make a connection with dimensional theories. Second, researcher are using different platforms to do their experiments, at time of writing, there is not a formal evidence that clarify the impact of the embodiment on the perception of emotions. This generates situations in which two works could not be comparable. Third, the use of actors to generate the movements are not reliable. Actors use diverse techniques to create believable representations of specific emotions. However, this does not ensure that all actor convey emotions in same way. Therefore, several records are done and the ones with the highest agreement are selected. This brings the technical question on how to interpret the significance of agreement obtained~\cite{Russell2003}. Fourth, there is not a generic format to present the finding and movements used. Each researcher is using diverse methodologies to present their findings, for example some uses Laban's theory~\cite{Sharma2013} while others present the postures~\cite{NAO2013}.  