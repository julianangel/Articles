%Most works in Human-Robot Interaction (HRI) focus their attention on faces and human-like bodies, due to the abundance of works in face elicitation in humans. Moreover, 
Some researchers in Human-Robot Interaction (HRI) use videos to evaluate their implementations of emotions. One of the most well-known expressive robots is Kismet~\cite{Breazeal2002}, a robotic face able to interact with people and show emotions. The face had enough degrees of freedom to portray the emotions suggested by Ekman~\cite{Ekman2004} (\textit{Happiness}, \textit{Surprise}, \textit{Anger}, \textit{Disgust}, \textit{Fear}, and \textit{Sadness}), plus \textit{Interest}. 
Despite the complex system behind Kismet, the emotion's projection evaluation was done using videos with a very limited number of participants. A similar approach was followed by Li and Chignell~\cite{Li2011}, who used videos of a teddy bear robot to study the contribution of arms and head movement to express emotions. In the same direction Destephe and collaborators~\cite{Destephe2013} studied the attribution of emotion to a robot's gait using a virtual representation of the platform WABIAN-2R. Knight and Simmons~\cite{knight2016} used two platforms (i.e., Keepon and NAO) with different degrees of freedom to study the possibility to project inner states with just head movements. Although the use of videos has the advantage to cover a major number of participants, they miss the impact created from the physical interaction between the participant and the platform.

%%%%%%%%%%%%%%%%%%%%%%%%
The use of real platforms to study emotion projection follows two paths, using both anthropomorphic and non-anthropomorphic platforms. 

The first path is characterized by the use of cue positions to project emotions~\cite{NAO2013}. In some cases, special attention has been taken to determine head's angle and arms' position contribution to specific emotion expressions~\cite{Brown2014}. 
Nevertheless, current humanoid platforms cannot generate smooth gaits, and this limits the quality of body movements. To overcome this limitation, some researchers have reduced the human resemblance (e.g., eliminating limbs and facial expressions) to increase platform mobility and study new mechanisms to project emotions~\cite{Arras2012}. Reducing even more the anthropomorphism, Saerbeck and Christoph used a Roomba platform to study the contribution of curvature in a trajectory to conceive emotional states~\cite{Saerbeck2010}. Similarly Lourens and Barakova~\cite{BarakovaL10} implemented a set of behaviors to determine the emotion  perceived from diverse movements, which were selected from the work done by Camurri et al.~\cite{pop00002}. Similarly, Barakova and collaborators~\cite{Barakova2013} created a closet in which lights could be manipulated to convey pre-defined behaviours. The robot's behaviours were defined using the Interpersonal Behaviour Circle (ICB). Their findings suggest that electronic systems can elicit a type of reactions different from the one expected by theories of interpersonal communication. Despite the type of platform used, these works offers an overview of features that could be used to express certain emotions, but they not give precise feature values to implement the emotions.

Other approaches have been adopted to get a better understanding of the contribution of diverse features to express emotions through movement. For example, Suk and collaborators payed a particular attention to speed, smoothness, granularity of movement path and volume of a non-bioinspired object~\cite{NAM2014}. Their results suggest that arousal increases as speed increases and that there is not any clear tendency for smoothness. On the other hand, granularity is positively correlated with pleasure and arousal, while volume is negatively correlated with pleasure and positively correlated with arousal. Alike, Tan and collaborators~\cite{Tan2016} have studied the contribution of velocity, fluidity, direction and orientation of a small box. Their results suggest that direction is directly correlated with dominance, but that fluidity does not influence the perception. While flat orientation is related to positive valence, leaning positions are related with negative valence. Finally, velocity is correlated with valence, arousal and dominance.  

Due to the popularity that quadrocopters have received in the last years, Sharma and collaborators~\cite{Sharma2013} used a quadrotor to study how different Laban's effort~\cite{Laban1968} parameters could impact on the perception of affection. A professional Laban certified actor was asked to generate 16 different paths, for each one changing one of the four Laban's parameters (space, weight, time, and flow). Each generated path was recorded using the Vicon motion-tracking system ad then replicated on the quadrocopter. Cauchard and collaborators~\cite{Cauchard2016} studied how flight paths could project personal traits and emotional attributes. All these works present a very nice starting point to identify features and values that could be used to project emotions in robotics, which could help in coordinating humans and robots~\cite{Novika2015}. However, these works do not give a clear guideline to elicit precise emotions. This could lead to implementations that express an undesired emotion~\cite{Angel2016}. For example, people could confuse an implementation of \textit{Happiness} with \textit{Anger}.